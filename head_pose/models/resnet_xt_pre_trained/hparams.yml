batch_size: 16
n_epochs: 300
patience: 30 #number of epochs wait until improvement
clipping: true #apply gradient clipping
min_delta: 0.01 #min delta of improvement for early stopping
start_fold: 0 #fold will be ran
verbose_train: true
num_workers: 2
model_name: resnetXt # CHANGE WHEN CREATE A NEW MODEL
checkpoint_path: ./data/model_weights/resnetXt/checkpoint # CHANGE WHEN CREATE A NEW MODEL
model_path: ./data/model_weights/resnetXt # CHANGE WHEN CREATE A NEW MODEL
model:
  n_channels: 1
  n_samples: 15000
  layer_feature_maps: [ 16, 32, 64, 128, 256 ]
  dropout_rate: 0.1
  pool_size: 2
  kernel_size: 3
  dilation: 1
optimizer_name: Adam
optimizer_hparams:
  lr: 0.001
  weight_decay: 0.0
#scheduler_name: CosineAnnealingLR
#scheduler_hparams:
#  T_max: 15
#  eta_min: 1.0e-09
#  last_epoch: -1
#  verbose: true
scheduler_name: ReduceLROnPlateau
scheduler_hparams:
  patience: 10
  threshold: 0.02
  verbose: true

